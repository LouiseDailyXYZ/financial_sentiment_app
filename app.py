import streamlit as st
from transformers import BertTokenizer, BertForSequenceClassification, pipeline
from newspaper import Article

@st.cache_resource
def load_model():
    model = BertForSequenceClassification.from_pretrained("ProsusAI/finbert")
    tokenizer = BertTokenizer.from_pretrained("ProsusAI/finbert")
    return pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)

nlp = load_model()

st.set_page_config(page_title="é‡‘èæƒ…æ„Ÿåˆ†æå™¨", layout="centered")
st.title("ğŸ“ˆ é‡‘èæ–‡ç« æƒ…æ„Ÿåˆ†æå™¨")
st.markdown("è¼¸å…¥ä¸€ç¯‡é‡‘èæ–°èé€£çµï¼Œè‡ªå‹•åˆ†æå…¶æƒ…ç·’æ˜¯æ­£é¢ã€è² é¢æˆ–ä¸­ç«‹ã€‚")

url = st.text_input("è«‹è¼¸å…¥æ–‡ç« é€£çµï¼ˆä¾‹å¦‚ Bloombergã€Reutersã€Yahoo Financeï¼‰")

if url:
    try:
        with st.spinner("â³ æ­£åœ¨æ“·å–æ–‡ç« å…§å®¹..."):
            article = Article(url)
            article.download()
            article.parse()
            text = article.text

        if not text:
            st.error("âŒ ç„¡æ³•æ“·å–å…§å®¹ï¼Œè«‹ç¢ºèªé€£çµæ˜¯å¦æ­£ç¢º")
        else:
            st.subheader("ğŸ“„ æ–‡ç« å…§å®¹")
            st.write(text[:1000] + ("..." if len(text) > 1000 else ""))

            st.subheader("ğŸ“Š æƒ…æ„Ÿåˆ†æçµæœ")
            result = nlp(text[:512])
            label = result[0]['label']
            score = round(result[0]['score'] * 100, 2)
            st.success(f"**{label}**ï¼ˆä¿¡å¿ƒå€¼ï¼š{score}%ï¼‰")

    except Exception as e:
        st.error(f"ğŸš¨ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
